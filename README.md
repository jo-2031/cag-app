# ğŸ’¡ CAG: Context-Aware Generation System

This project is a **Context-Aware Generation (CAG)** system built with **FastAPI**, **Redis**, and **Streamlit**, powered by a **Large Language Model (LLM)**. It caches generated responses using Redis and intelligently retrieves them based on semantic similarity â€” even when user queries are phrased differently but have the same meaning.

---

## ğŸš€ Features

- ğŸ” **Redis Caching**  
  Avoids repeated generation by caching LLM responses based on semantic similarity.

- ğŸ§  **LLM Integration**  
  Uses a language model to dynamically generate context-aware responses.

- ğŸŒ **FastAPI Backend**  
  Handles API requests and manages response logic.

- ğŸ¨ **Streamlit Frontend**  
  Provides a simple and intuitive user interface.


---

## ğŸ§± Tech Stack

- **Frontend**: Streamlit
- **Backend**: FastAPI
- **Cache**: Redis
- **LLM**: (OpenAI / LLaMA / any pluggable LLM)
- **Vector Search**: Sentence embedding similarity

